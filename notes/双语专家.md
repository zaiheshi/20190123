### 双语专家

#### **翻译质量评估**

- 句子级的评估: 回归模型
- 单词级的评估: 分类模型

#### 系统

－　注意力机制加上Transfomer 机器翻译的模型框架，在前人研究的基础上提出了一种名为『Bilingual Expert』model (『双语专家』模型) 作为**特征抽取器**，联合基于神经网络的**译文质量评估框架**。

#### 特征抽取模型

- 从原文与译文语句中抽取足够的信息或特征，并用来进一步计算译文效果到底好不好
- 特征抽取模型在输入原句序列和目标句序列的条件下抽取质量评估特征，这一部分的训练需要使用一般的双语平行数据集。而特征抽取模型抽取的特征可继续用于评估翻译效果，这一部分需要使用质量评估（QE）数据集，该数据集不仅包括原句与译文句，同时还包括了标注的翻译质量。
- 条件语言模型: 给定原语句子所有词和目标语句除当前词以外的上下文，模型希望能使用这些词的信息预测出当前词
- 如果译文的质量非常高，那么这种基于条件语言模型的词预测模型能基于原句子和目标句子的上下文准确预测出当前词。相反如果译文质量不高，那么模型很难基于上下文准确地预测出当前词
- 给定原语句子和目标语句子的上下文，并预测目标语句子的当前词可以表述为如下方程式
  - ![img](https://image.jiqizhixin.com/uploads/editor/58afe5f1-8ebe-4e62-ba4d-eb69e0e1e1ec/1533189220632.png)
  - 传统的双向 LSTM 模型被替换为Transformer：挖掘序列内部的隐藏关系　＋　提高并行效率，
- LSTM的词预测模型
  - ![img](https://image.jiqizhixin.com/uploads/editor/ab11b962-3fb4-4e91-ac95-227a71b9d8bf/1533189220728.png)
  - 对于原语句子 x，模型首先将每一个词都表征为词嵌入向量，然后再馈送到正向和反向两条 LSTM，每一个时间步需要同时结合正向和反向 LSTM 的隐藏状态并作为最终的输出。对于目标语句子 y，在第 j 个词之前的序列使用正向 LSTM 建模，而第 j 个词之后的序列使用反向的 LSTM 建模。最后在预测第 j 个词时，需要使用原语句子 x 的上下文向量 c_j（由注意力机制得出）、目标语前一个词及前面序列的语义信息、目标语后一个词及后面序列的语义信息。
- Transformer的架构：在原文和译文端之间进行注意力机制的计算，同时原文和译文内部也引入自注意力的机制，使得两端深层的语义信息能够很好得被学习到。
- 编码过程：Transformer的编码过程，由相同的两个模块构成，每一个模块都有两个子层级。其中第一个子层级是 Multi-Head 自注意机制，第二个子层级采用了全连接网络，其主要作用在于注意子层级的特征。同时，每一个子层级都会添加残差连接和层级归一化。
- 解码过程: 创新之处，基于 Multi-head Attention 的双向解码，每个方向的解码器也由相同的两个模块堆叠而成，与编码器**区别**的是，每一个解码器模块都有**三个子层**组成。第一个和第三个子层分别与编码器的 Multi-Head 自注意力层和全连接层相同，而**第二个子层采用了 Multi-Head Attention 机制**，**使用编码器的输出作为 Key 和 Value，使用解码模块第一个子层的输出作为 Query**。与编码器**类似**的是，每一个子层同样会加上残差连接与层级归一化模块。该思想可以理解**构造了一个双向的 Transformer**，而其真正作用不是翻译系统中的解码器，而更像一个编码器或者特征表示器。
- Transformer 编码器的 Inputs 为原语句子序列 x，解码器输入的 Outputs 为目标语正向和逆向两个序列，解码器中 Softmax 输出的概率表示目标端当前词预测。在阿里采用的架构中，编码器和解码器的层数都等于 2
- 每一次在预测目标语的当前词时，Transformer 需要使用正向与反向两部分信息，　若当前预测目标语的第 j 个词，对于正向序列而言，模型需要使用目标端第 j-1 个词的前向深层语义特征向量和第 j-1 个词的词向量。而对于反向序列而言，模型需要使用目标端第 j+1 个词的反向深层语义特征向量与第 j+1 个词的词向量
- mis-matching features
  - ![img](https://image.jiqizhixin.com/uploads/editor/cbcbf060-4259-4352-a695-9203ea5b9bbb/1533189220794.png)
  - 当某个翻译结果错误单词不多的时候，预训练模型会给出正确的单词预测分布，这和翻译结果激活的单词会存在一个 gap。这个 gap 是一个非常重要的特征，阿里机器翻译团队的实验显示就算只用这个特征去做下一步预测，也可以得到很好的结果
  - 在预测第 j 个词时，j+1 和 j-1 两个深层语义特征向量都相当于使用预训练的语言模型抽取语言特征，而那两个词的词嵌入向量则保留了原始信息。
- 除了需要预测最可能的当前词，更重要的是需要通过质量评估特征向量为后续运算迁移足够的语言知识。因此阿里的模型从词预测模型中抽取了两种质量评估特征
  - ![2019-01-20-142709_780x828_scrot](/home/eve/2019-01-20-142709_780x828_scrot.png)
  - 其中正向和反向深层语义特征都从 Transformer 的解码器中抽出,
    - 正向语义特征 ![img](https://image.jiqizhixin.com/uploads/editor/00e564fb-1ae1-4164-943f-026955b1705e/1533189220544.png) 包含了原语序列的所有信息和目标语第 k 个词之前的语义信息
    - 反向语义特征 ![img](https://image.jiqizhixin.com/uploads/editor/345c45a6-08dc-4bb3-abc8-73442e33b99d/1533189221330.png) 包含了原语序列的所有信息和目标语第 k 个词之后的语义信息
    - 同时，深层语义特征还包含第 k-1 个词的词义信息 ![img](https://image.jiqizhixin.com/uploads/editor/a26b3b99-d1e2-4470-8e2d-4ef2afb2a5cf/1533189221428.png) 和第 k+1 个词的词义信息 ![img](https://image.jiqizhixin.com/uploads/editor/0280d750-56bf-4648-8190-14655bff62a1/1533189221681.png)
    - 在基于『双语专家』条件语言模型的词预测模型的预测解码环节，阿里机器翻译团队利用以上所有深层语义表达，重构了目标语 (Token Reconstruction)。所以如果我们强制解码为真实的词语，就可以取特征信息 ![img](https://image.jiqizhixin.com/uploads/editor/f05925e0-8603-4563-94ca-46d88570db8e/1533189221747.png)。不强制解码，保留模型预测最可能出现的词语，我们就能得到特征信息 ![img](https://image.jiqizhixin.com/uploads/editor/d08cccc9-9821-44d7-9100-16fbb545a48a/1533189222031.png)。剩下的两种特征则描述了 m_k 与 i_max 之间的关系。

#### 质量评估模型

- 在抽取了质量评估特征后，它们可以与人工抽取的特征一起作为质量评估模型或 Quality Estimator 的输入来计算译文质量
- 条件语言模型的特征抽取模型和质量评估模型合在一起的缺陷：
  - 很多人工添加的特征是无法使用的(包括句长、标点符号数量、句子语言模型分数等17个特征)
  - 特征抽取模型广泛使用的平行语料与质量评估模型使用的 QE 数据集有比较大的不匹配性，联合训练可能会产生较差的性能。(平行语料只包含正确的目标语句子，而 QE 数据集同时包含正确与不正确的目标语句子)
- 将所有特征向量都拼接在一起，且每一个特征向量视为一个时间步，那么我们就能以如下方式利用从原文与译文中抽取的语义信息
  - ![img](https://image.jiqizhixin.com/uploads/editor/f5506032-4b99-4f8e-9054-9e3db4788d70/1533189222186.png)
  - 基于双向 LSTM，模型预测的目标即句子层面的翻译质量和单词层面的翻译对错,  这两个任务除了评估阶段采用的架构不一样，其它如特征抽取等过程都是一样的。
    - 在句子层面中，biLSTM 编码的前向的最后一个时间步与后向的最后一个时间步的隐藏特征联合计算一个实数值以表示翻译质量
    - 在词语层面, biLSTM 编码对应的目标端词的每一个时间步的前后向量隐藏特征联合计算一个值以将它们分类为 OK 或 BAD

#### 数据集

- 词预测模型所使用的**平行数据集**和评估模型所使用的 **QE 数据集**
  - 平行数据集可以在广泛的领域收集, 目的是训练一个能抽取语言语义信息的模型，这很类似于预训练一个强大的语言模型。 QE 训练数据只有 1 至 3 万, 远远不够，通过**构造30万左右的QE训练伪数据**，这部分数据与真实 QE 数据合并训练完质量评估基线模型后，会再使用真实的 QE 数据微调模型，即使用一个在大的数据集上预训练好的模型在真实场景数据上微调。
- 构造的伪数据：参考APE的方法，采用了一种 round-trip translation 的技术
  - 先从大量单语数据中筛选出领域相关的单语，作为人工后编辑译文 PE；同时用双语语料训练两个 MT 系统
  - 将筛选的领域单语先通过一个 MT 系统生成原文 SRC；SRC 再通过另一个 MT 系统生成译文 MT
  - 这样两次调取 MT 结果的方法，生成了一批原文，译文和人工后编辑译文组合的 APE 数据，称为 APE 训练伪数据， 然后通过 TER 工具生成了对应的 HTER 分数和词标注，构造出了 QE 伪数据
  - 为了更好地模拟真实数据，根据真实 QE 数据的 HTER 分布，从构造的伪数据中随机挑选出 30 万
  - 这些伪数据先与真实的 QE 数据一起训练一个 Quality Estimator 的基础 Baseline 模型，再单独用真实的 QE 数据 fine tune 模型
  - 